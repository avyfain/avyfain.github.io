---
title: "On hyper-personalization"
main_image: nyc2024/previews/40.jpeg
layout: post
category: articles
tags: [tools, technology, ai, programming]
description: Imagine each of us surrounded by content, tools, and teachers that know us intimately and reflect us back perfectly, but which have little in common with what others are experiencing.
---

At a team dinner a few weeks ago, our CTO asked: *how will the world change in the next five years in ways that aren't obvious?* Answers were all over the place, everywhere from imminent WWIII over rare-earths to humanoid robots at home. My answer was more mundane: ubiquitous hyper-personalization.

We're all familiar with the "Facebook and Google are listening" narrative that comes from targeted ads. This kind of personalization exists today, with advertisers A/B testing and optimizing bandits for engagement and conversion. My hypothesis was that while today they serve us existing ad inventory, soon every ad will be generated for individuals in real-time. Big tech already enables this with copy experimentation on their platforms. Eventually this will grow to multimodal ads including images, video, and audio in the voice of your podcast host[^1]. Their optimization problem is no longer how to best auction off our attention among N existing items of ad inventory, but auctioning off the slots to whoever is most confident they can generate a match that will get us to click.

Someone else answered saying that Cursor, Claude, Lovable, and similar tools that take user input to write code will disappear. Their view was that models would instead go directly from user input to compiled byte-code, skipping the high level languages that humans can code and read. This is also a hyper-personalization use case. Today's models answer to the same prompt from different people with different outputs thanks to memory and context, but expect us to tweak the results to our specific needs. When you remove every intermediate layer, understanding who's asking becomes the whole problem. Context becomes everything.

At some point in the conversation, someone brought up AI in education, and how it could be used to customize learning experiences. They gave the example of a student struggling with math, and how after identifying the concepts they have most trouble with, the AI would provide them with customized exercises and explanations. Not all teachers are equally good for everyone, but the curriculum is set, so the problem to solve is what's the right teacher or method to teach a given student. Yes, there's an asymptotic curve to learning, but we can compress it by picking the right explanations.

That, I think, is the deeper story. Moving from a shared world of mass media, standard curricula, and common interfaces to a fragmented one. Each of us surrounded by content, tools, and teachers that know us intimately and reflect us back perfectly, but which have little in common with what others are experiencing.  

<hr>

<small>
<em>Photo: Flock, by me. Previously posted on [New York, 2024](/photos/2025/02/17/nyc2024/).
</em></small>


[^1]:  As I wrote this, I was surprised how few startups are tackling this problem. Omneky might be furthest along, and newer YC startups like Kestroll and Crux are going after the same space, but it’s tough to compete with Meta and Google’s distribution.

